<!-- #### Submitted

- <strong>S. Li</strong>, X. Yang*, A. Cao*, K. Fan, Y. Liu, C. Wang, and Q. Niu. LaNCoR: Label Noise-Contrastive Robust Learning for Seismic Signal Processing with Application to Microseismic Arrival Time Picking. <strong>Rej :)</strong> [[Code]](https://github.com/senli1073/LaNCor)

#### Published

- X. Yang, <strong>S. Li</strong>, A. Cao*, C. Wang*, Y. Liu, X. Bai, and Q. Niu (2024). Deep Transfer Learning for P-wave Arrival Identification and Automatic Seismic Source Location in Underground Mines. <strong>International Journal of Rock Mechanics and Mining Sciences</strong>. [[Paper]](https://doi.org/10.1016/j.ijrmms.2024.105888)

- <strong>S. Li</strong>, X. Yang*, A. Cao*, C. Wang, Y. Liu, Y. Liu, and Q. Niu (2024). SeisT: A Foundational Deep-Learning Model for Earthquake Monitoring Tasks. <strong>IEEE Transactions on Geoscience and Remote Sensing</strong>. [[Paper]](https://doi.org/10.1109/TGRS.2024.3371503) [[Code]](https://github.com/senli1073/SeisT)

- A. Cao, X. Yang, C. Wang*, <strong>S. Li</strong>, Y. Liu, L. Dou, and Q. Niu (2023). High-Precision Phase Picking and Automatic Source Locating Method for Seismicity in Mines Based on Deep Transfer Learning. <strong>Journal of China Coal Society</strong>. [[Paper]](https://doi.org/10.13225/j.cnki.jccs.2023.0095)

- A. Cao, Y. Liu, X. Yang*, <strong>S. Li</strong>, C. Wang, X. Bai, and Y. Liu (2022). Physical Index and Data Fusion-Driven Method for Coal Burst Prediction in Time Sequence. <strong>Journal of China Coal Society</strong>. [[Paper]](https://doi.org/10.13225/j.cnki.jccs.2022.0680)

- X. Yang, X. Yu, C. Zhang, <strong>S. Li</strong>, and Q. Niu (2021). MineGPS: Battery-Free Localization Base Station for Coal Mine Environment. <strong>IEEE Communications Letters</strong>. [[Paper]](https://doi.org/10.1109/LCOMM.2021.3081593)
 -->

<!-- ### Preprints

- **Shaoguang Wang**, Z. Chen, Y. Xu, W. Guo, H. Xiong. (2025). Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration. *arXiv preprint arXiv:2508.03337*. (In preparation for CVPR 2026) [[Paper]](https://arxiv.org/abs/2508.03337)

### Conference Papers

- W. Guo, Z. Chen, **Shaoguang Wang**, J. He, Y. Xu, J. Ye, Y. Sun, H. Xiong. (2025). Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding. In *Advances in Neural Information Processing Systems (NeurIPS 2025)*. [[Paper]](https://arxiv.org/abs/2503.13139)

### Surveys

- W. Guo, G. Sun, J.X. He, T. Shao, **Shaoguang Wang**, et al. (2025). A Survey of fMRI to Image Reconstruction. *arXiv preprint arXiv:2502.16861*. [[Paper]](https://arxiv.org/abs/2502.16861) -->

<!-- ---
layout: default
---

## Publications

--- -->

<div style="display: flex; margin-bottom: 2em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/less_is_more_figure.png" alt="Less is More Diagram" style="width: 100%;">
    </div>
    <div style="flex: 1;">
        <strong>Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration</strong><br>
        <strong>Shaoguang Wang</strong>, Z. Chen, Y. Xu, W. Guo, H. Xiong.<br>
        <em>arXiv preprint arXiv:2508.03337. (In preparation for CVPR 2026)</em><br>
        <p>This work tackles the token-inefficiency problem in MLLM-based Video-QA. We propose Adaptive Frame-Pruning (AFP), a novel framework that intelligently prunes redundant video frames and compensates for information loss with a lightweight semantic graph, achieving significant efficiency gains while often improving accuracy.</p>
        [<strong>Paper</strong>](https://arxiv.org/abs/2508.03337) | [<strong>Code (Coming Soon)</strong>]
    </div>
</div>

---

<div style="display: flex; margin-bottom: 2em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/logic_in_frames_figure.png" alt="Logic-in-Frames Diagram" style="width: 100%;">
    </div>
    <div style="flex: 1;">
        <strong>Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding</strong><br>
        W. Guo, Z. Chen, <strong>Shaoguang Wang</strong>, J. He, Y. Xu, J. Ye, Y. Sun, H. Xiong.<br>
        <em>Advances in Neural Information Processing Systems (<strong>NeurIPS 2025</strong>).</em><br>
        <p>This paper introduces a semantics-driven search framework for identifying keyframes in long videos. By decomposing a query into logical components and verifying them in the video, the method enhances understanding through explicit logical relationships. My contribution focused on the logical verification module.</p>
        [<strong>Paper</strong>](https://arxiv.org/abs/2503.13139) | [<strong>OpenReview</strong>](https://openreview.net/forum?id=yONFNHGoeP)
    </div>
</div>

---

<div style="display: flex; margin-bottom: 2em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/fmri_survey_figure.png" alt="fMRI Survey Diagram" style="width: 100%;">
    </div>
    <div style="flex: 1;">
        <strong>A Survey of fMRI to Image Reconstruction</strong><br>
        W. Guo, G. Sun, J.X. He, T. Shao, <strong>Shaoguang Wang</strong>, et al.<br>
        <em>arXiv preprint arXiv:2502.16861.</em><br>
        <p>This work provides a systematic review of the rapidly evolving field of fMRI-to-image reconstruction. It discusses key methodologies, datasets, and the primary challenges in decoding human visual perception from brain signals, providing a valuable resource for researchers entering this interdisciplinary field.</p>
        [<strong>Paper</strong>](https://arxiv.org/abs/2502.16861)
    </div>
</div>
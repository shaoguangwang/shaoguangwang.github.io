<!-- Publication 1 -->
<div class="pub-item">
<div class="pub-media">
<img src="static/assets/img/less_is_more_figure.png" alt="Less is More Diagram">
</div>
<div class="pub-content">
<div class="pub-title">Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration</div>
<div>
<strong>Shaoguang Wang</strong>, Z. Chen, Y. Xu, W. Guo, H. Xiong.
</div>
<div style="font-style: italic; color: #666; margin-top: 4px;">arXiv preprint.</div>
<div class="pub-desc">
This work tackles the token-inefficiency problem in MLLM-based Video-QA. We propose Adaptive Frame-Pruning (AFP), a novel framework that intelligently prunes redundant video frames and compensates for information loss with a lightweight semantic graph, achieving significant efficiency gains while often improving accuracy.
</div>
<div class="pub-links">
<a href="https://arxiv.org/abs/2508.03337" target="_blank">[Paper]</a>
<span>[Code (Coming Soon)]</span>
</div>
</div>
</div>

<!-- Publication 2 -->
<div class="pub-item">
<div class="pub-media">
<img src="static/assets/img/logic_in_frames_figure.png" alt="Logic-in-Frames Diagram">
</div>
<div class="pub-content">
<div class="pub-title">Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding</div>
<div>
W. Guo, Z. Chen, <strong>Shaoguang Wang</strong>, J. He, Y. Xu, J. Ye, Y. Sun, H. Xiong.
</div>
<div style="font-style: italic; color: #666; margin-top: 4px;">Advances in Neural Information Processing Systems (<strong>NeurIPS 2025</strong>).</div>
<div class="pub-desc">
This paper introduces a semantics-driven search framework for identifying keyframes in long videos. By decomposing a query into logical components and verifying them in the video, the method enhances understanding through explicit logical relationships. My contribution focused on the logical verification module.
</div>
<div class="pub-links">
<a href="https://arxiv.org/abs/2503.13139" target="_blank">[Paper]</a>
<a href="https://github.com/guoweiyu/Logic-in-Frames" target="_blank">[GitHub]</a>
</div>
</div>
</div>

<!-- Publication 3 -->
<div class="pub-item">
<div class="pub-media">
<img src="static/assets/img/fmri_survey_figure.png" alt="fMRI Survey Diagram">
</div>
<div class="pub-content">
<div class="pub-title">A Survey of fMRI to Image Reconstruction</div>
<div>
W. Guo, G. Sun, J.X. He, T. Shao, <strong>Shaoguang Wang</strong>, et al.
</div>
<div style="font-style: italic; color: #666; margin-top: 4px;">arXiv preprint.</div>
<div class="pub-desc">
This work provides a systematic review of the rapidly evolving field of fMRI-to-image reconstruction. It discusses key methodologies, datasets, and the primary challenges in decoding human visual perception from brain signals, providing a valuable resource for researchers entering this interdisciplinary field.
</div>
<div class="pub-links">
<a href="https://arxiv.org/abs/2502.16861" target="_blank">[Paper]</a>
</div>
</div>
</div>



<!-- <div style="display: flex; align-items: flex-start; margin-bottom: 2.5em; border-bottom: 1px solid #e0e0e0; padding-bottom: 2em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/less_is_more_figure.png" alt="Less is More Diagram" style="width: 100%; border-radius: 5px;">
    </div>
    <div style="flex: 1;">
        <strong>Less is More: Token-Efficient Video-QA via Adaptive Frame-Pruning and Semantic Graph Integration</strong><br>
        <strong>Shaoguang Wang</strong>, Z. Chen, Y. Xu, W. Guo, H. Xiong.<br>
        <em>arXiv preprint.</em><br>
        <p style="margin-top: 0.5em;">
        This work tackles the token-inefficiency problem in MLLM-based Video-QA. We propose Adaptive Frame-Pruning (AFP), a novel framework that intelligently prunes redundant video frames and compensates for information loss with a lightweight semantic graph, achieving significant efficiency gains while often improving accuracy.
        </p>
        <p style="margin-top: 1em;">
        [<strong><a href="https://arxiv.org/abs/2508.03337" target="_blank">Paper</a></strong>] | [<strong>Code (Coming Soon)</strong>]
        </p>
    </div>
</div>

---

<div style="display: flex; align-items: flex-start; margin-bottom: 2.5em; border-bottom: 1px solid #e0e0e0; padding-bottom: 2em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/logic_in_frames_figure.png" alt="Logic-in-Frames Diagram" style="width: 100%; border-radius: 5px;">
    </div>
    <div style="flex: 1;">
        <strong>Logic-in-Frames: Dynamic Keyframe Search via Visual Semantic-Logical Verification for Long Video Understanding</strong><br>
        W. Guo, Z. Chen, <strong>Shaoguang Wang</strong>, J. He, Y. Xu, J. Ye, Y. Sun, H. Xiong.<br>
        <em>Advances in Neural Information Processing Systems (<strong>NeurIPS 2025</strong>).</em><br>
        <p style="margin-top: 0.5em;">
        This paper introduces a semantics-driven search framework for identifying keyframes in long videos. By decomposing a query into logical components and verifying them in the video, the method enhances understanding through explicit logical relationships. My contribution focused on the logical verification module.
        </p>
        <p style="margin-top: 1em;">
        [<strong><a href="https://arxiv.org/abs/2503.13139" target="_blank">Paper</a></strong>] | [<strong><a href="https://github.com/guoweiyu/Logic-in-Frames" target="_blank">GitHub</a></strong>]
        </p>
    </div>
</div>

---

<div style="display: flex; align-items: flex-start; margin-bottom: 2.5em;">
    <div style="flex: 0 0 30%; margin-right: 2em;">
        <img src="/static/assets/img/fmri_survey_figure.png" alt="fMRI Survey Diagram" style="width: 100%; border-radius: 5px;">
    </div>
    <div style="flex: 1;">
        <strong>A Survey of fMRI to Image Reconstruction</strong><br>
        W. Guo, G. Sun, J.X. He, T. Shao, <strong>Shaoguang Wang</strong>, et al.<br>
        <em>arXiv preprint.</em><br>
        <p style="margin-top: 0.5em;">
        This work provides a systematic review of the rapidly evolving field of fMRI-to-image reconstruction. It discusses key methodologies, datasets, and the primary challenges in decoding human visual perception from brain signals, providing a valuable resource for researchers entering this interdisciplinary field.
        </p>
        <p style="margin-top: 1em;">
        [<strong><a href="https://arxiv.org/abs/2502.16861" target="_blank">Paper</a></strong>]
        </p>
    </div>
</div> -->

